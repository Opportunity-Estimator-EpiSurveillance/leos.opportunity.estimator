{
    "collab_server" : "",
    "contents" : "#!/usr/bin/env Rscript --vanilla\n# Notification delay modelling\n# Leo Bastos\n# \n#\n\n# N_t - number of notified cases at time t\n# Y_{t,d} - number of notified cases from time t with notification delay d\n# D - maximum acceptable time delay\n\n# N_t = Y_{t,0} + \\sum_{d=1}^{D} Y_{t,d}\n\n# Y_{0,t} is known forall t\n# If T is today, Y_{t,d} is unknown for all (t,d) such that t+d > T\n\n# Contributtors\n# Claudia T Codeço and Marcelo F C Gomes\n# Load auxiliary functions\nsource(\"../data_filter/episem.R\")\nsource('./lastepiweek.R')\nsource('./generate.estimates.R')\nsource('./post.thresholds.R')\nsource('./post.sum.R')\n\n## Read command line arguments\nsuppressPackageStartupMessages(library(\"argparse\"))\n# create parser object\nparser <- ArgumentParser()\n# specify our desired options\n# by default ArgumentParser will add an help option\nparser$add_argument(\"-p\", \"--percentile\", type=\"double\", default=95,\n                    help=\"Percentile to use as delay distribution threshold [default %(default)s]\")\nparser$add_argument(\"-d\", \"--date\", type=\"character\", default=format(Sys.Date(), '%Y-%m-%d'),\n                    help=\"Date to use as base, in format YYYY-MM-DD [default Sys.Date()]\")\n# get command line options, if help option encountered print help and exit,\n# otherwise if options not found on command line then set defaults,\nargs <- parser$parse_args()\n\n# Set quantile target for delay distribution:\nquantile.target <- args$percentile / 100\n\n# Read data and filter columns\nd <- droplevels(subset(read.csv(\"../clean_data/clean_data_epiweek.csv\", check.names = F, encoding='utf-8'),\n                       select=c(SG_UF_NOT, DT_NOTIFIC_epiyearweek, DT_NOTIFIC_epiyear,\n                                DT_NOTIFIC_epiweek, DT_DIGITA_epiyear, DT_DIGITA_epiweek)))\n\n# Discard years before 2013:\nd <- droplevels(subset(d, DT_NOTIFIC_epiyear >= 2013))\n\n# Calculate opportunity between notification and upload:\nd$DelayWeeks <- d$DT_DIGITA_epiweek - d$DT_NOTIFIC_epiweek +\n  (d$DT_DIGITA_epiyear - d$DT_NOTIFIC_epiyear)*as.integer(sapply(d$DT_NOTIFIC_epiyear,lastepiweek))\n\n# Discard notifications with delay greater than 6 months (> 26 weeks)\nd <- na.exclude(d[d$DelayWeeks < 27, ])\n\n# Latest week with closed counts on DT_DIGITA is actualy the previous one\ntoday <- episem(args$date)\nlyear <- as.integer(strsplit(today, 'W')[[1]][1])\ntoday.week <- as.integer(strsplit(today, 'W')[[1]][2])\ntoday.week <- ifelse(today.week > 1, today.week-1, as.integer(lastepiweek(lyear-1)))\ntoday <- paste0(lyear,'W',today.week)\n\n# Discar incomplete data from the current week\nd <- d[d$DT_DIGITA_epiyear < lyear | (d$DT_DIGITA_epiyear==lyear & d$DT_DIGITA_epiweek<=today.week), ]\n\n# Read population profile:\nd_pop <- read.csv('../data/PROJECOES_2013_POPULACAO-simples_agebracket.csv', check.names = F, encoding='utf-8')\n\n# Create entries for regional aggregates:\nd$Region <- mapply(function(x) as.character(unique(d_pop[d_pop$`Código`==as.character(x),'Região'])), d$SG_UF_NOT)\nd$Country <- 'BR'\n\n# Grab target quantile from delay distribution for each UF\ndelay.topquantile <- c(ceiling(with(d, tapply(DelayWeeks, SG_UF_NOT, FUN = function(x,...) max(8,quantile(x,...)),\n                                            probs=quantile.target))),\n                       ceiling(with(d, tapply(DelayWeeks, Region, FUN = function(x,...) max(8,quantile(x,...)),\n                                              probs=quantile.target))),\n                       ceiling(with(d, tapply(DelayWeeks, Country, FUN = function(x,...) max(8,quantile(x,...)),\n                                              probs=quantile.target))))\n\n# Read activity thresholds:\ndf.thresholds <- read.csv('../clean_data/mem-report.csv', check.names = F, encoding='utf-8')\nlow.activity <- df.thresholds[is.na(df.thresholds$`se típica do início do surto`),'UF']\n\n# Read weekly data:\nd_weekly <- read.csv('../clean_data/clean_data_epiweek-weekly-incidence.csv', check.names = F, encoding='utf-8')\nd_weekly <- d_weekly[d_weekly$sexo == 'Total', c('UF', 'epiyear', 'epiweek', 'SRAG', 'Tipo')]\nd_weekly['DT_NOTIFIC_epiyearweek'] <- mapply(function(x,y) paste0(x,'W',sprintf(\"%02d\",y)), d_weekly$epiyear,d_weekly$epiweek)\n# # Fill all epiweeks:\nfyear <- min(d_weekly$epiyear)\nyears.list <- c(fyear:lyear)\ndf.epiweeks <- data.frame(DT_NOTIFIC_epiyearweek=character(), UF=factor())\n# List of locations:\nuf_list <- unique(d_weekly$UF)\nfor (y in years.list){\n  epiweeks <- c()\n  lweek <- ifelse(y < lyear, as.integer(lastepiweek(y)), today.week)\n  for (w in c(1:lweek)){\n    epiweeks <- c(epiweeks, paste0(y,'W',sprintf('%02d', w)))\n  }\n  for (uf in uf_list){\n    df.epiweeks <- rbind(df.epiweeks, data.frame(list(DT_NOTIFIC_epiyearweek=epiweeks, UF=uf)))\n  }\n}\n\nd_weekly <- merge(df.epiweeks, d_weekly, by=c('DT_NOTIFIC_epiyearweek', 'UF'), all.x=T)\nd_weekly[is.na(d_weekly$epiweek), 'epiweek'] <- mapply(function (x) as.integer(strsplit(as.character(x[[1]]), 'W')[[1]][2]), \n                                                       d_weekly[is.na(d_weekly$epiweek), 'DT_NOTIFIC_epiyearweek'])\nd_weekly[is.na(d_weekly$epiyear), 'epiyear'] <- mapply(function (x) as.integer(strsplit(as.character(x[[1]]), 'W')[[1]][1]), \n                                                       d_weekly[is.na(d_weekly$epiyear), 'DT_NOTIFIC_epiyearweek'])\n\nd_weekly[is.na(d_weekly)] <- 0\nd_weekly$Situation <- 'stable'\nd_weekly[,c(\"mean\",\"50%\",\"2.5%\",\"97.5%\")] <- d_weekly$SRAG\n\n# Thresholds:\nthres.cols <- c('limiar pré-epidêmico','intensidade alta','intensidade muito alta')\naux2 <- t(mapply(FUN=function(uf, inc) \n  post.thresholds(inc, lims=as.numeric(df.thresholds[df.thresholds$UF==as.character(uf),thres.cols])),\n  d_weekly$UF, d_weekly$SRAG) )\nthres.prob.cols <- colnames(aux2)\nd_weekly[,thres.prob.cols] <- aux2\n\n# Check if plot folder exists\nrequire(scales)\nif (!dir.exists('./plots')) {\n  dir.create(file.path('./plots'), showWarnings = FALSE)\n}\n# Load palette\nrequire(RColorBrewer)\ncores <- colorRampPalette((brewer.pal(9, 'Oranges')))(27)\n\n# Prepare filled epiweeks data frame:\n# # Fill all epiweeks:\nfyear <- min(d$DT_NOTIFIC_epiyear)\nyears.list <- c(fyear:lyear)\ndf.epiweeks <- data.frame(DT_NOTIFIC_epiyearweek=character())\nfor (y in years.list){\n  epiweeks <- c()\n  lweek <- ifelse(y < lyear, as.integer(lastepiweek(y)), today.week)\n  for (w in c(1:lweek)){\n    epiweeks <- c(epiweeks, paste0(y,'W',sprintf('%02d', w)))\n  }\n  df.epiweeks <- rbind(df.epiweeks, data.frame(list(DT_NOTIFIC_epiyearweek=epiweeks)))\n}\nrownames(df.epiweeks) <- df.epiweeks$DT_NOTIFIC_epiyearweek\n\n# List of locations:\nuf_list <- unique(d$SG_UF_NOT)\nreg_list <- unique(d$Region)\ncntry_list <- unique(d$Country)\n\nfor (uf in c(uf_list, reg_list, cntry_list)){\n  if (!dir.exists(file.path('./plots',uf))) {\n    dir.create(file.path('./plots',uf), showWarnings = FALSE)\n  }\n  \n  # Plot UF's delay distribution\n  qthreshold <- delay.topquantile[as.character(uf)]\n  if (uf %in% uf_list){\n    d.tmp <- droplevels(subset(d, SG_UF_NOT==uf))\n  } else if (uf %in% reg_list){\n    d.tmp <- droplevels(subset(d, Region==uf))\n  } else {\n    d.tmp <- droplevels(subset(d, Country==uf))\n  }\n  svg(paste0('./plots/',uf,'/delay_pattern.svg'))\n  histo <- hist(d.tmp$DelayWeeks, breaks=c(0:27), plot=F)\n  barplot.fig <- barplot(histo$density, xlab = \"Delay (weeks)\", ylab = \"Notifications frequency\",\n                         xaxs='i', yaxs='i')\n  abline(v=barplot.fig[qthreshold], col='gray')\n  axis(1, at = barplot.fig, labels = c(1:length(barplot.fig)) )\n  text(x=barplot.fig[qthreshold], y=.55*max(histo$density), 'Dmax', srt=90, pos=2)\n  dev.off()\n  \n  # Prepare delay table\n  aux <- tapply(d.tmp$DelayWeeks >= 0, INDEX = list(d.tmp$DT_NOTIFIC_epiyearweek), FUN = sum, na.rm = T)\n  delay.tbl.tmp <- data.frame(Notifications = aux[order(rownames(aux))])\n  \n  for(k in 0:26){  \n    aux <- tapply(d.tmp$DelayWeeks == k, INDEX = d.tmp$DT_NOTIFIC_epiyearweek, FUN = sum, na.rm = T)\n    delay.tbl.tmp[paste(\"d\",k, sep=\"\")] <- aux[order(rownames(aux))]\n  }\n  \n  delay.tbl.tmp <- merge(df.epiweeks, delay.tbl.tmp, by=0, all.x=T)\n  delay.tbl.tmp[is.na(delay.tbl.tmp)] <- 0\n  rownames(delay.tbl.tmp) <- delay.tbl.tmp$Row.names\n  \n  # Plot UF's time series\n  svg(paste0('./plots/',uf,'/timeseries.svg'))\n  # # Time series\n  fyear = min(d.tmp$DT_NOTIFIC_epiyear)\n  lyear = max(d.tmp$DT_NOTIFIC_epiyear)\n  plot(delay.tbl.tmp$Notifications , type = \"l\", axes=F, xlab=\"Time\", ylab=\"Notifications\")\n  axis(2)\n  axis(1, at = seq(0,52*(lyear-fyear+1),52) ,labels = fyear:(lyear+1))\n  dev.off()\n\n  # Plot time series with delay profile\n  svg(paste0('./plots/',uf,'/delay_timeseries.svg'))\n  delay.week <- paste(\"d\",0:26, sep=\"\")\n  barplot.fig <- barplot(t(as.matrix(delay.tbl.tmp[,delay.week])), beside = F, col=cores, axisnames = F,\n                         xlab  =  \"Time\", ylab = \"Notifications\", border = NA)\n  lines(x=barplot.fig,y=delay.tbl.tmp$d0, type = \"l\")\n  axis(1, at = barplot.fig[seq(1,53*(lyear-fyear+1),52)] , labels = c(fyear:(lyear+1)) )\n  #legend(x='topright', legend = c(seq(0,25,5)), fill=cores[seq(1,26,5)], pch = '.')\n  dev.off()\n  \n  ##################################################################\n  # Preparing the data to be modelled\n  ##################################################################\n  \n  # Time index of the unknown counts (Dmax+1,...,Tactual) \n  uf.indexes <- rownames(d_weekly[d_weekly$UF==as.character(uf),])\n  Tactual <- length(uf.indexes)\n  index.time <- uf.indexes[(Tactual-qthreshold+1):Tactual]\n  \n  if (!(uf %in% low.activity)) {\n    \n    # Calculate estimates\n    df.tbl.tmp.estimates <- generate.estimates(delay.tbl.tmp, Dmax=qthreshold, do.plots=T, uf=uf)\n    \n    # Generate quantiles estimates\n    aux2 <- round(t(apply(df.tbl.tmp.estimates$samples,1,FUN = post.sum)))\n\n    # Calculate corresponding incidence\n    years <- d_weekly[index.time, 'epiyear']\n    pop <- sapply(years, FUN=function(x) d_pop$Total[d_pop$`Código`==uf & d_pop$Ano==x])\n    aux2 <- aux2*100000/pop\n    \n    # For estimated region, update with obtained predictions\n    d_weekly[index.time, 'Situation'] <- 'estimated'\n    d_weekly[index.time,colnames(aux2)] <- aux2\n    \n    # Calculate probability of falling in each activity region\n    # Obtain location's thresholds\n    uf.threshold <- as.numeric(df.thresholds[df.thresholds$UF == as.character(uf), c(\"limiar pré-epidêmico\",\n                                                                                     \"intensidade alta\",\n                                                                                     \"intensidade muito alta\")])\n    uf.threshold.absolute <- uf.threshold*d_pop[d_pop[,'Código']==uf & d_pop$Ano==lyear, 'Total']/100000\n    d_weekly[index.time,thres.prob.cols] <- t(apply(df.tbl.tmp.estimates$samples,1,FUN = post.thresholds, lims = uf.threshold.absolute ))\n  \n  } else {\n    d_weekly[index.time, 'Situation'] <- 'unknown'\n  }\n  \n}\n\nif (!dir.exists(file.path('../clean_data'))) {\n  dir.create(file.path('../clean_data'), showWarnings = FALSE)\n}\n\nd_weekly[,'Run date'] <- Sys.Date()\nwrite.csv(d_weekly, file=file.path('../clean_data/',paste0(today,'estimated_values.csv')), na='', row.names = F,\n          encoding='utf-8')\nwrite.csv(d_weekly, file='../clean_data/current_estimated_values.csv', na='', row.names = F, encoding='utf-8')\ndf.Dmax <- data.frame(list(UF=names(delay.topquantile), epiyearweek=today, Dmax=delay.topquantile, Execution=Sys.Date()))\nifelse(file.exists('../clean_data/Dmax.csv'), print.col.names <- F, print.col.names <- T)\nwrite.table(df.Dmax, file='../clean_data/Dmax.csv', sep=',', quote=F, na='', row.names = F, col.names = print.col.names,\n            append=T, encoding='utf-8')",
    "created" : 1485890143770.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "3914225883",
    "id" : "6CAF761",
    "lastKnownWriteTime" : 1485527757,
    "last_content_update" : 1485527757,
    "path" : "~/codes/opportunity_estimator/chainladder_inla_Influenza_simples_v1.R",
    "project_path" : null,
    "properties" : {
    },
    "relative_order" : 8,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}